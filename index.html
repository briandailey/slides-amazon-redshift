<!doctype html>
<html lang="en">

    <head>
        <meta charset="utf-8">

        <title>Amazon Redshift: What You Need To Know (PyTennessee 2014)</title>

        <meta name="description" content="Amazon Redshift: The basics, what you need to know to get started, and some caveats.">
        <meta name="author" content="Brian Dailey">

        <meta name="apple-mobile-web-app-capable" content="yes" />
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <link rel="stylesheet" href="css/reveal.min.css">
        <link rel="stylesheet" href="css/theme/default.css" id="theme">

        <!-- For syntax highlighting -->
        <link rel="stylesheet" href="lib/css/zenburn.css">

        <!-- If the query includes 'print-pdf', use the PDF print sheet -->
        <script>
            document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
        </script>

        <!--[if lt IE 9]>
        <script src="lib/js/html5shiv.js"></script>
        <![endif]-->
    </head>

    <body>

        <div class="reveal">

            <!-- Any section element inside of this container is displayed as a slide -->
            <div class="slides">
                <section data-background="img/stars.jpg">
                    <h1>Amazon Redshift</h1>
                    <h3>What You Need To Know</h3>
                    <p>
                    <small>
                        PyTN 2014<br/>
                        <a href="http://www.flickr.com/photos/nasamarshall/5095567894/in/photostream/">Photo: NASA</a>
                    </small>
                    </p>
                </section>

                <section>
                    <h3>Who Is This Guy?</h3>
                    <h4>Brian Dailey</h4>
                    <p>CTO &amp; Co-founder at Stratasan</p>
                    <p>
                        Monkeys around a bit with Python, PostgreSQL,<br/>
                        Django, and a few more bits and pieces.
                    </p><p>
                        <a href="http://twitter.com/byeliad">@byeliad</a>
                    </p>
                    <aside class="notes">A little about me, get this out of the way quickly.</aside>
                </section>

                <section>
                    <h3>toc</h3>
                    <ul>
                        <li>What is Redshift?</li>
                        <li>Why We Use It</li>
                        <li>Cost Overview</li>
                        <li>Rough Benchmarks</li>
                        <li>Redshift Architecture</li>
                    </ul>
                    <aside class="notes">I always like to tell you what I'm going to tell you first.</aside>
                </section>

                <section>
                    <ul>
                        <li>Building Tables</li>
                        <li>Distribution and Sort Keys</li>
                        <li>Loading Data</li>
                        <li>Querying Data</li>
                        <li>Extracting Data</li>
                        <li>Optimization Tips</li>
                        <li>Web UI</li>
                    </ul>
                </section>

                <!-- Example of nested vertical slides -->
                <section>
                    <h2>What's Redshift?</h2>
                </section>
                <section>
                    <h3>bizspeak:</h3>
                    <p><q cite="https://aws.amazon.com/redshift/">
                        Amazon Redshift is a fast, fully managed, petabyte-scale data warehouse service ...
                    </q></p>
                </section>
                <section>
                    <img width="320" height="299" src="img/haha-business.jpg" alt="Ha ha business!">
                </section>
                <section>
                    <p>"It achieves its high performance through extreme parallelism, columnar data storage, and smart data compression." - <a href="http://nerds.airbnb.com/redshift-performance-cost">AirBnB</a></p>
                </section>
                <section>
                    <h3>Why we use it</h3>
                    <ul>
                        <li>It looks a lot like PostgreSQL</li>
                        <li>Much cheaper than analytic appliances (Vertica et al)</li>
                        <li>Easy and fast ad-hoc aggregate queries</li>
                    </ul>
                    <aside class="notes">
                        The learning curve was short for us to get started.
                        Vertica was fairly expensive, longer learning curve. See the AirBNB writeup.
                        Since it uses columnar storage, sums, avgs, counts are quite fast.
                    </aside>
                </section>
                <section>
                    <h3>If this is Postgres:</h3>
                    <img src="img/edward-500.jpg" alt="normal">
                </section>
                <section>
                    <h3>This is Redshift:</h3>
                    <div class="vertical-align: middle;">
                    <img src="img/edward-wax.png" alt="wax" style="display: inline; vertical-align: middle;" align="middle">
                    +
                    <img src="img/formula_1-300.jpg" alt="F1" style="display: inline; vertical-align: middle;" align="middle">
                </div>
                </section>

                <section>
                    <h3>What's it Cost?</h3>
                </section>

                <section style="font-size: 80%;">
                    <table><colgroup><col style="width: 16%"><col style="width: 14%"><col style="width: 14%"><col style="width: 14%"><col style="width: 14%"><col style="width: 14%"><col style="width: 14%"></colgroup><caption>US East (N. Virginia)</caption><thead><tr><th></th><th class="rate">vCPU</th><th class="rate">ECU</th><th class="rate">Memory (GiB)</th><th class="rate">Storage</th><th class="rate">I/O</th><th class="rate">Price</th></tr></thead><tbody class="body"><tr class="heading"><th colspan="7" class="type">DW1 - Dense Storage</th></tr><tr class="tiers"><td class="size">dw1.xlarge</td><td class="vCPU">2</td><td class="ECU">4.4</td><td class="memory">15</td><td class="storage">2TB HDD</td><td class="io">0.30GB/s</td><td class="rate yrTerm1Hourly">$0.850 per Hour</td></tr><tr class="tiers"><td class="size">dw1.8xlarge</td><td class="vCPU">16</td><td class="ECU">35</td><td class="memory">120</td><td class="storage">16TB HDD</td><td class="io">2.40GB/s</td><td class="rate yrTerm1Hourly">$6.800 per Hour</td></tr></tbody><tbody class="body"><tr class="heading"><th colspan="7" class="type">DW2 - Dense Compute</th></tr><tr class="tiers"><td class="size">dw2.large</td><td class="vCPU">2</td><td class="ECU">7</td><td class="memory">15</td><td class="storage">0.16TB SSD</td><td class="io">0.20GB/s</td><td class="rate yrTerm1Hourly">$0.250 per Hour</td></tr><tr class="tiers"><td class="size">dw2.8xlarge</td><td class="vCPU">32</td><td class="ECU">104</td><td class="memory">244</td><td class="storage">2.56TB SSD</td><td class="io">3.70GB/s</td><td class="rate yrTerm1Hourly">$4.800 per Hour</td></tr></tbody></table>
                </section>

                <section style="font-size: 80%;">
                    <h3>Per Terabyte</h3>
                    <table width="100%"><caption>US East (N. Virginia)</caption><thead><tr><th></th><th colspan="3" class="yrTerm">Effective Price per TB per Year</th></tr><tr><th></th><th class="type">On-Demand</th><th class="type">1yr RI</th><th class="type">3yr RI</th></tr></thead><tbody class="body"><tr class="tiers"><td class="tier">dw1.xlarge</td><td class="price OD">$3,723 </td><td class="price 1yRI">$2,192 </td><td class="price 3yRI">$999 </td></tr><tr class="tiers"><td class="tier">dw1.8xlarge</td><td class="price OD">$3,723 </td><td class="price 1yRI">$2,192 </td><td class="price 3yRI">$999 </td></tr><tr class="tiers"><td class="tier">dw2.large</td><td class="price OD">$13,688 </td><td class="price 1yRI">$8,794 </td><td class="price 3yRI">$5,498 </td></tr><tr class="tiers"><td class="tier">dw2.8xlarge</td><td class="price OD">$16,425 </td><td class="price 1yRI">$11,018 </td><td class="price 3yRI">$5,498 </td></tr></tbody></table>
                </section>

                <section>
                    <h1>Speed</h1>
                </section>

                <section>
                    <h1>PostgreSQL 9.1.9</h1>
                    <pre><code># select count(*) from dummy_table;
+----------+
|  count   |
+----------+
| 21454134 |
+----------+
(1 row)
Time: 586931.216 ms
</code></pre>
                    ~10 minutes
                </section>

                <section>
                    <h1>Redshift</h1>
                    <pre><code># select count(*) from dummy_table;
  count
----------
 21454134
(1 row)
Time: 1561.359 ms
</code></pre>
                    1.5 seconds
                </section>

                <section>
                    <h1>PostgreSQL 9.1.1</h1>
<!-- waiting-->

                    <pre><code># select count(*), year, avg(total_charges) \
    from dummy_table group by year order by year desc;
+---------+------+---------+
|  count  | year |   avg   |
+---------+------+---------+
| 4926225 | 2012 | 6144.37 |
| 8280484 | 2011 | 6149.85 |
| 8247425 | 2010 | 5673.83 |
+---------+------+---------+
(3 rows)
Time: 850491.316 ms
</code></pre>
                    ~15 minutes
                </section>

                <section>
                    <h1>Redshift</h1>
                    <pre><code># select count(*), year, avg(total_charges) \
    from dummy_table group by year order by year desc;
  count  | year |   avg
---------+------+---------
 4926225 | 2012 | 6144.37
 8280484 | 2011 | 6149.85
 8247425 | 2010 | 5673.83
(3 rows)
Time: 5887.693 ms
</code></pre>
                    5.8 seconds
                </section>

                <section>
                    <p>AirBnB tested against Hadoop...</p>
                </section>

                <section>
                    <p>"Simple range query against a giant table with 3 billion rows, we saw 5x performance improvement over Hive!"</p>
                </section>


                <section>
                    <h1>What It's Good For</h1>
                </section>
                <section><h3>Analytics</h3></section>
                <section><h1>... And not good for</h1></section>
                <section><h3>Your web application</h3></section>

                <section>
                <h1>Redshift<br/>
                    Architecture</h1>
                </section>

                <section>
                    <a href="http://docs.aws.amazon.com/redshift/latest/dg/c_high_level_system_architecture.html"><img src="img/redshift-architecture.png" alt="redshift architecture" /></a>
                </section>

                <section data-background="img/composer.png">
                    <h1>Leader Node</h1>
                    <p><small><a href="http://www.flickr.com/photos/frederikmagle/6880669820/">Photo: Frederik Magle</a></small></p>
                </section>
                <section data-background="img/symphony.jpg">
                    <h1>Compute Nodes</h1>
                    <p><small><a href="http://www.flickr.com/photos/paulrobinsonuk/8406097564/">Photo: Paul Robinson</a></small></p>
                </section>

                <section>
                    <h3>Types of nodes...</h3>
                    <ol>
                        <li>XL: 2 cores, 15GiB memory, 3 disk drives with 2TB of local attached storage.</li>
                        <li>8XL: 16 cores, 120GiB memory, 24 disk drives (16TB)</li>
                        <li><b>(New)</b> SSD XL:  - 160 GB of SSD storage, 2 Intel Xeon E5-2670v2 virtual cores, and 15 GiB of RAM.</li>
                        <li><b>(New)</b> SSD 8XL:  - 2.56 TB of SSD storage, 32 Intel Xeon E5-2670v2 virtual cores, and 244 GiB of RAM.</li>
                    </ol>
                </section>

                <section>
                <ul>
                    <li>Each node has multiple slices (one for each core)</li>
                    <li>Executes queries in parallel over each slice</li>
                    <li>Data is divvied up to each slice by a distribution key...</li>
                </ul>
                </section>

                <section>
                    <h2>Building Tables</h2>
                </section>

                <section data-background="img/anarchy.jpg">
                    <h1>unenforced<br/>constraints</h1>
                    <p><a href="http://www.flickr.com/photos/80497449@N04/7383943916/">Photo: Nicolas Raymand</a></p>
                </section>
                <section data-background="img/anarchy.jpg">
                    <p><q cite="http://docs.aws.amazon.com/redshift/latest/dg/c_best-practices-defining-constraints.html">“Amazon Redshift does not enforce unique, primary-key, and foreign-key constraints.”</q></p>
                </section>
                <section>
                    <h3>unsupported types</h3>
                    <ul>
                        <li>Arrays</li>
                        <li>INTERVAL, TIME, TIMESTAMP WITH TIMEZONE</li>
                        <li>SERIAL, MONEY</li>
                        <li>XML</li>
                        <li>UUID</li>
                        <li><a href="http://docs.aws.amazon.com/redshift/latest/dg/c_unsupported-postgresql-datatypes.html">...and more...</a></li>
                    </ul>
                </section>
                <section>
                    <h3>supported types</h3>
                    <ul>
                        <li>SMALLINT</li>
                        <li>INTEGER</li>
                        <li>BIGINT</li>
                        <li>DECIMAL</li>
                        <li>REAL</li>
                        <li>DOUBLE PRECISION</li>
                        <li>BOOLEAN</li>
                        <li>CHAR</li>
                        <li>VARCHAR</li>
                        <li>DATE</li>
                        <li>TIMESTAMP</li>
                        <li><b>(New)</b> JSON</li>
                    </ul>
                </section>
                <section>
                    <img src="img/dragons-small.jpg" alt="Dragons" />
                    <!-- There be some dragons here. -->
                </section>
                <section>
                    <blockquote cite="http://docs.aws.amazon.com/redshift/latest/dg/r_Character_types.html#r_Character_types-char-or-character">
                        "CHAR and VARCHAR data types are defined<br/>
                        in terms of bytes, not characters."</blockquote>
                </section>
                <section>
                    <h3>Distribution Key</h3>
                    <ul>
                        <li>Default is round robin / even distribution.</li>
                        <li>Otherwise, like values are stored together.</li>
                        <li>Aim is to distribute data evenly across slices.</li>
                    </ul>
                </section>
                <section>
                    <h3>Sort Key</h3>
                    <blockquote cite="http://docs.aws.amazon.com/redshift/latest/dg/c_best-practices-sort-key.html">Amazon Redshift stores your data on disk in sorted order according to the sort key.</blockquote>
                </section>
                <section data-background="img/jobs.jpg">
                    <h2>One more thing...</h2>
                    <ul>
                        <li>You can't ALTER COLUMN.</li>
                        <li>Only one ADD COLUMN per ALTER TABLE.</li>
                    </ul>
                    <br/>
                    <br/>
                    <p><small>Photo credit: <a href="http://www.flickr.com/photos/acaben/541420967/" title="Steve Jobs Keynote by acaben, on Flickr">Ben Stanfield</a></small></p>
                </section>

                <section>
                    <h1>Loading Data Into Redshift</h1>
                </section>

                <section>
                    <h2>Your Options</h2>
                    <ul>
                        <li>S3</li>
                        <li>DynamoDB</li>
                    </ul>
                </section>

                <section>
                    <h3>Best Practice</h3>
                    <h1>S3</h1>
                    <h4>(Per Amazon)</h4>
                </section>

                <section>
                    <h3>s3cmd is your friend.</h3>
                    <p><a href="http://s3tools.org/s3cmd">http://s3tools.org/s3cmd</a></p>
                    <pre><code>s3cmd put gigantic_csv_file.csv.part_00*gz s3://mybucket/mypath/</code></pre>
                </section>

                <section>
<pre><code style="word-wrap: break-word;">COPY table_name [ (column1 [,column2, ...]) ]
FROM 's3://objectpath'
[ WITH ] CREDENTIALS [AS] 'aws_access_credentials'
[ option [ ... ] ]</code></pre>
                </section>

                <section>
                    <ul>
                        <li><i>objectpath</i> is a prefix. Loads in parallel.</li>
                        <li>gzip</li>
                        <li>encryption</li>
                    </ul>
                </section>

                <section>
                    <h2>Debugging</h2>
                    <ul>
                        <li>STL_LOAD_ERRORS</li>
                        <li>STL_LOADERROR_DETAIL</li>
                        <li>STL_S3CLIENT</li>
                    </ul>
                </section>

                <section>
                    <h2>Debugging</h2>
                    <ul>
                        <li>NOLOAD</li>
                        <li>MAXERROR</li>
                    </ul>
                </section>

                <section>
                    <img src="img/dragons-small.jpg" alt="Dragons" />
                    <!-- There be some dragons here. -->
                </section>

                <section>
                    <p>You need 2.5x data size to load if sorted or to vacuum table.</p>
                </section>

                <section>
                    <p>Date or timestamp columns must be formatted in same way (only defined once).</p>
                    <p>(ACCEPTANYDATE will load NULL when format does not match.)</p>
                </section>

                <section>
                    <p>Ingest via SQL</p>
                    <p>Sure...</p>
                </section>

                <section>
                    <img src="img/wtf-is-wrong-with-you.jpg" alt="WTF is wrong with you?" />
                </section>


                <section>
                    <h1>QUERYING DATA</h1>
                </section>

                <section><h3>Looks/smells like Postgres 8.0.2.</h3></section>

                <section>
                    <ul>
                        <li>AVG(INT) will return INT.</li>
                        <li>Note that this is NOT listed in "Features implemented differently."</li>
                    </ul>
                </section>

                <section>
                    <h1>EXTRACTING DATA</h1>
                </section>

                <section>
<pre><code style="word-wrap: break-word;">unload ('select * from tablename')
to 's3://mybucket/'
credentials 'aws_access_key_id=[your-access-key-id];
aws_secret_access_key=[your-secret-access-key]';
</code></pre>
                </section>

                <section>
                    <p>UNLOAD dumps to multiple files</p>
                    <pre><code>s3://bucket/table_data_0000
s3://bucket/table_data_0000</code></pre>
                </section>

                <section>
                    <p>...unless you trick it.</p>
                    <pre><code>unload ('select * from (
select * from ... where ...) limit 2147483647') ...</code></pre>
                </section>

                <section>
                    <p>But if you're over 5.8GiB, files will still split.</p>
                    <p>It's also slower.</p>
                </section>

                <section>
                    <h1>Optimization</h1>
                </section>

                <section>
                    <h4>Workload Manager (WLM)</h4>
                    <p>Controls concurrent queries. Less  means more memory per process.</p>
                    <p>"By default, a cluster is configured with one queue that can run five queries concurrently."</p>
                    <!-- http://docs.aws.amazon.com/redshift/latest/dg/cm-c-defining-query-queues.html -->
                </section>

                <section>
                    <h3>VACUUM (ANALYZE)</h3>
                    <p>Vacuum early, vacuum often.</p>
                    <p>Anytime you've made non-trivial changes to data.</p>
                </section>

                <section>
                    <p>VACUUM is expensive. Schedule for slow days.</p>
                </section>

                <section>
                    <p>Only one VACUUM at a time per cluster.</p>
                </section>

                <section>
                    <p>VACUUM doesn't resort unaffected slices.</p>
                </section>

                <section>
                    <p>Debugging VACUUM</p>
                    <ul>
                        <li>svv_vacuum_progress</li>
                        <li>svv_vacuum_summary</li>
                    </ul>
                </section>

                <section>
                    <p>Size your columns appropriately.</p>
                </section>

                <section>
                    <p>DATE or TIMESTAMP > CHAR</p>
                </section>

                <section><p>Test different configurations!</p>
                    <ul>
                        <li>2 8XL nodes?</li>
                        <li>Or 16 XL nodes?</li>
                    </ul>
                </section>

                <section><h2>Web UI</h2></section>
                <section><img src="img/redshift_create_cluster_1.png" alt="create cluster" /></section>
                <section><img src="img/redshift_create_cluster_2.png" alt="create cluster" /></section>
                <section><img src="img/redshift_create_cluster_3.png" alt="create cluster" /></section>
                <section><img src="img/redshift_performance_console.png" alt="Performance console" /></section>
                <section><img src="img/redshift_queries.png" alt="Queries" /></section>
                <section><img src="img/redshift_query_detail.png" alt="Query Detail" /></section>
                <section><img src="img/redshift_copies.png" alt="Copying" /></section>
                <section><img src="img/redshift_copy_detail.png" alt="Copy detail" /></section>

                <section><h1>Wrapping up</h1></section>

                <section><h2>Redshift is cost-effective.</h2></section>
                <section><h2>...fast.</h2></section>
                <section><h2>...familiar.</h2></section>

                <section>
                    <h1>Redshift</h1>
                    <h3>Nice balance!</h3>
                </section>

                <section>
                <p>"In fact, our analysts like Redshift so much that they don’t want to go back to Hive and other tools even though a few key features are lacking in Redshift. Also, we have noticed that big joins of billions of rows tend to run for a very long time, so for that we’d go back to hadoop for help." -- <a href="http://nerds.airbnb.com/redshift-performance-cost">AirBnB</a></p>
                </section>

                <section>
                <p>"Oddly enough, Redshift isn’t going to sell because devs think it’s super-duper-whizz-bang. It’s going to sell because it took a problem and an industry famous for it’s opaque pricing, high TCO, and unreliable results and completely turned it on its head." -- <a href="http://blog.aggregateknowledge.com/2013/05/16/aws-redshift-how-amazon-changed-the-game/">AK Tech Block</a></p>
                </section>

                <section>
                    <h1>THE END</h1>
                    <h2>Thanks!</h2>
                    <h3>Questions? Tomatoes?</h3>
                    <p>
                    <a href="http://www.twitter.com/byeliad">@byeliad</a><br/>
                    <a href="http://github.com/briandailey">github.com/briandailey</a><br/>
                    </p>
                    <p>Thanks to <a href="http://www.twitter.com/jasonamyers">@jasonamyers</a> for suffering through my first draft.</p>
                </section>

            </div>

        </div>

        <script src="lib/js/head.min.js"></script>
        <script src="js/reveal.min.js"></script>

        <script>

            // Full list of configuration options available here:
            // https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                controls: true,
                progress: true,
                history: true,
                center: true,

                theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
                transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

                // Optional libraries used to extend on reveal.js
                dependencies: [
                    { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
                    { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
                    // { src: 'plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; } }
                    // { src: 'plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
                ]
            });

        </script>

    </body>
</html>
